{"cells":[{"cell_type":"markdown","id":"3b680107-3234-4a42-9e25-678172e238dd","metadata":{"id":"3b680107-3234-4a42-9e25-678172e238dd"},"source":["### Packages"]},{"cell_type":"code","execution_count":null,"id":"ce8e50d7-7564-4dc1-8b41-f30c0b4ad63f","metadata":{"id":"ce8e50d7-7564-4dc1-8b41-f30c0b4ad63f"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from PIL import Image"]},{"cell_type":"markdown","id":"c7430ace-50fb-46a8-9ce0-81e697d32e29","metadata":{"id":"c7430ace-50fb-46a8-9ce0-81e697d32e29"},"source":["### 이미지 데이터 전처리"]},{"cell_type":"code","execution_count":null,"id":"1ea88f26-8e23-4bd6-9e51-577abf98a118","metadata":{"id":"1ea88f26-8e23-4bd6-9e51-577abf98a118"},"outputs":[],"source":["# 데이터 경로 설정\n","fun_path = \"/Users/euijinlee/KDT_DATA/파이널프로젝트/data1/fun\"          # 즐거운\n","healing_path = \"/Users/euijinlee/KDT_DATA/파이널프로젝트/data1/healing\"  # 힐링\n","mood_path = \"/Users/euijinlee/KDT_DATA/파이널프로젝트/data1/mood\"        # 감성적인"]},{"cell_type":"code","execution_count":null,"id":"7c7195ec-254d-496c-bd41-81a4ce7f9586","metadata":{"id":"7c7195ec-254d-496c-bd41-81a4ce7f9586"},"outputs":[],"source":["# 이미지 크기 및 채널 설정\n","img_size = (224, 224)\n","channels = 3"]},{"cell_type":"code","execution_count":null,"id":"76894cc3-baab-4ea4-8336-4e06776c618b","metadata":{"id":"76894cc3-baab-4ea4-8336-4e06776c618b"},"outputs":[],"source":["# 이미지 데이터 로드 및 전처리\n","def load_and_preprocess_data(image_paths, label, img_size=(224, 224)):\n","    data = []\n","    labels = []\n","\n","    for img_path in image_paths:\n","        try:\n","            # Skip non-image files\n","            if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n","                continue\n","\n","            img = Image.open(img_path)\n","            img = img.convert('RGB')  # Ensure the image is in RGB mode\n","            img = img.resize(img_size)\n","            img_array = np.array(img)  # Convert PIL Image to NumPy array\n","            img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n","\n","            data.append(img_array)\n","            labels.append(label)\n","\n","        except Exception as e:\n","            print(f\"Error processing image {img_path}: {str(e)}\")\n","\n","    return np.array(data), np.array(labels)"]},{"cell_type":"code","execution_count":null,"id":"f244629e-4a7d-4e55-94ca-58867d9f1de5","metadata":{"id":"f244629e-4a7d-4e55-94ca-58867d9f1de5"},"outputs":[],"source":["fun_images = [os.path.join(fun_path, img) for img in os.listdir(fun_path)]\n","healing_images = [os.path.join(healing_path, img) for img in os.listdir(healing_path)]\n","mood_images = [os.path.join(mood_path, img) for img in os.listdir(mood_path)]\n","\n","fun_data, fun_labels = load_and_preprocess_data(fun_images, label=0)\n","healing_data, healing_labels = load_and_preprocess_data(healing_images, label=1)\n","mood_data, mood_labels = load_and_preprocess_data(mood_images, label=2)"]},{"cell_type":"markdown","id":"0f8ad9cf-0bee-4566-a37b-5c08e8159755","metadata":{"id":"0f8ad9cf-0bee-4566-a37b-5c08e8159755"},"source":["### 학습/테스트 데이터 분할"]},{"cell_type":"code","execution_count":null,"id":"a9052c53-00d6-4d72-86d0-29160604aad5","metadata":{"id":"a9052c53-00d6-4d72-86d0-29160604aad5"},"outputs":[],"source":["# 데이터 합치기 및 레이블 변환\n","X = np.concatenate([fun_data, healing_data, mood_data], axis=0)\n","y = np.concatenate([fun_labels, healing_labels, mood_labels], axis=0)\n","\n","# 레이블을 범주형 형태로 변환\n","y = to_categorical(y, num_classes=3)"]},{"cell_type":"code","execution_count":null,"id":"98da8dae-45e9-4cac-a36e-d9bbff50904a","metadata":{"id":"98da8dae-45e9-4cac-a36e-d9bbff50904a"},"outputs":[],"source":["# 학습 및 테스트 데이터로 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","id":"e83ada47-7c35-41bf-ad48-1b0e79616737","metadata":{"id":"e83ada47-7c35-41bf-ad48-1b0e79616737"},"source":["### 모델링\n","- Test Loss: 2.2566311359405518, Test Accuracy: 0.5625"]},{"cell_type":"code","execution_count":null,"id":"d8a2c879-bf55-47b1-b4a4-afbf4491bed1","metadata":{"id":"d8a2c879-bf55-47b1-b4a4-afbf4491bed1"},"outputs":[],"source":["# CNN 모델 생성\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(3, activation='softmax'))  # 분류 클래스 수에 맞게 설정"]},{"cell_type":"code","execution_count":null,"id":"acc2170e-dd87-4a4f-9d98-a312d089978c","metadata":{"id":"acc2170e-dd87-4a4f-9d98-a312d089978c"},"outputs":[],"source":["# 모델 컴파일\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"4f67a010-ff5d-4a69-996c-a150798813ad","metadata":{"id":"4f67a010-ff5d-4a69-996c-a150798813ad","outputId":"30ffc192-e35c-4334-ba6c-48eeccf04cd5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","76/76 [==============================] - 23s 293ms/step - loss: 1.6908 - accuracy: 0.3943 - val_loss: 1.0943 - val_accuracy: 0.4095\n","Epoch 2/10\n","76/76 [==============================] - 22s 288ms/step - loss: 0.9739 - accuracy: 0.5275 - val_loss: 1.0279 - val_accuracy: 0.4786\n","Epoch 3/10\n","76/76 [==============================] - 24s 316ms/step - loss: 0.7961 - accuracy: 0.6439 - val_loss: 0.9692 - val_accuracy: 0.5691\n","Epoch 4/10\n","76/76 [==============================] - 23s 300ms/step - loss: 0.5061 - accuracy: 0.8063 - val_loss: 1.0818 - val_accuracy: 0.5789\n","Epoch 5/10\n","76/76 [==============================] - 22s 291ms/step - loss: 0.2708 - accuracy: 0.9116 - val_loss: 1.4509 - val_accuracy: 0.5691\n","Epoch 6/10\n","76/76 [==============================] - 22s 293ms/step - loss: 0.1672 - accuracy: 0.9589 - val_loss: 1.5598 - val_accuracy: 0.5839\n","Epoch 7/10\n","76/76 [==============================] - 22s 284ms/step - loss: 0.1075 - accuracy: 0.9766 - val_loss: 2.3430 - val_accuracy: 0.5214\n","Epoch 8/10\n","76/76 [==============================] - 22s 284ms/step - loss: 0.0768 - accuracy: 0.9864 - val_loss: 2.1996 - val_accuracy: 0.5757\n","Epoch 9/10\n","76/76 [==============================] - 21s 283ms/step - loss: 0.0407 - accuracy: 0.9918 - val_loss: 2.4954 - val_accuracy: 0.5740\n","Epoch 10/10\n","76/76 [==============================] - 21s 281ms/step - loss: 0.0533 - accuracy: 0.9905 - val_loss: 2.2566 - val_accuracy: 0.5625\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x2cfd93f10>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# 모델 학습\n","model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"]},{"cell_type":"code","execution_count":null,"id":"9d731c51","metadata":{"id":"9d731c51","outputId":"d4d26c02-3d9e-4a63-deab-575470ccde39"},"outputs":[{"name":"stdout","output_type":"stream","text":["19/19 [==============================] - 2s 80ms/step\n","19/19 [==============================] - 1s 77ms/step - loss: 2.2566 - accuracy: 0.5625\n","Test Loss: 2.2566311359405518, Test Accuracy: 0.5625\n"]}],"source":["# 테스트 데이터에 대한 예측 수행\n","predictions = model.predict(X_test)\n","\n","# 모델 평가\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"]},{"cell_type":"markdown","id":"0f8b4b94-01eb-4299-9a39-36f5df5a264a","metadata":{"id":"0f8b4b94-01eb-4299-9a39-36f5df5a264a"},"source":["### 예시 이미지로 테스트"]},{"cell_type":"code","execution_count":null,"id":"c0f435b9","metadata":{"id":"c0f435b9","outputId":"f61d1d23-5892-4cfc-d52f-68b0cac37a53"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 55ms/step\n","Predicted class: 2\n","Predicted label: mood\n"]}],"source":["from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","# 이미지 로드 및 전처리\n","img_path = r\"/Users/euijinlee/KDT_DATA/파이널프로젝트/data1/trial/fun_trial_1.jpg\"\n","img = image.load_img(img_path, target_size=(224, 224))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)\n","img_array /= 255.0  # 이미지 정규화\n","\n","# 모델에 입력 이미지 전달하여 예측 수행\n","predictions = model.predict(img_array)\n","\n","# 예측 결과 확인\n","predicted_class = np.argmax(predictions, axis=1)\n","print(\"Predicted class:\", predicted_class[0])\n","\n","class_mapping = {0: \"fun\", 1: \"healing\", 2: \"mood\"}\n","predicted_label = class_mapping[predicted_class[0]]\n","print(\"Predicted label:\", predicted_label)"]},{"cell_type":"code","execution_count":null,"id":"8fe8e9e0","metadata":{"id":"8fe8e9e0","outputId":"15a8f5c9-8e37-47e8-9080-690a30c808c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 23ms/step\n","Predicted class: 1\n","Predicted label: healing\n"]}],"source":["from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","# 이미지 로드 및 전처리\n","img_path = r\"/Users/euijinlee/KDT_DATA/파이널프로젝트/data1/trial/healing_trial_1.jpeg\"\n","img = image.load_img(img_path, target_size=(224, 224))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)\n","img_array /= 255.0  # 이미지 정규화\n","\n","# 모델에 입력 이미지 전달하여 예측 수행\n","predictions = model.predict(img_array)\n","\n","# 예측 결과 확인\n","predicted_class = np.argmax(predictions, axis=1)\n","print(\"Predicted class:\", predicted_class[0])\n","\n","class_mapping = {0: \"fun\", 1: \"healing\", 2: \"mood\"}\n","predicted_label = class_mapping[predicted_class[0]]\n","print(\"Predicted label:\", predicted_label)"]},{"cell_type":"code","execution_count":null,"id":"d3512334-a5f5-43da-8bad-26fe7226ba60","metadata":{"id":"d3512334-a5f5-43da-8bad-26fe7226ba60","outputId":"6110628e-16c2-4a3b-dd57-0c561afe911c"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 20ms/step\n","Predicted class: 0\n","Predicted label: fun\n"]}],"source":["from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","# 이미지 로드 및 전처리\n","img_path = r\"/Users/euijinlee/KDT_DATA/파이널프로젝트/data1/trial/mood_trial_1.jpeg\"\n","img = image.load_img(img_path, target_size=(224, 224))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)\n","img_array /= 255.0  # 이미지 정규화\n","\n","# 모델에 입력 이미지 전달하여 예측 수행\n","predictions = model.predict(img_array)\n","\n","# 예측 결과 확인\n","predicted_class = np.argmax(predictions, axis=1)\n","print(\"Predicted class:\", predicted_class[0])\n","\n","class_mapping = {0: \"fun\", 1: \"healing\", 2: \"mood\"}\n","predicted_label = class_mapping[predicted_class[0]]\n","print(\"Predicted label:\", predicted_label)"]},{"cell_type":"markdown","id":"3a478fed-9a98-4c83-93c2-23a9fd47e458","metadata":{"id":"3a478fed-9a98-4c83-93c2-23a9fd47e458"},"source":["### Save"]},{"cell_type":"code","execution_count":null,"id":"522a399f","metadata":{"id":"522a399f","outputId":"bf53ed47-9471-4470-f5ba-f0a3624198c9"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["#모델 저장\n","model.save('cnn_02_leeeug.h5')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}