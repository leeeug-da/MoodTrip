{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94debb19-8e0c-434f-a2ac-39c1147fe3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "150/150 [==============================] - 471s 3s/step - loss: 2.2215 - accuracy: 0.2279 - val_loss: 1.6701 - val_accuracy: 0.2817\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 387s 3s/step - loss: 1.5845 - accuracy: 0.3465 - val_loss: 1.4960 - val_accuracy: 0.3817\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 341s 2s/step - loss: 1.4516 - accuracy: 0.4092 - val_loss: 1.4490 - val_accuracy: 0.4317\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 320s 2s/step - loss: 1.3427 - accuracy: 0.4704 - val_loss: 1.1945 - val_accuracy: 0.5575\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 330s 2s/step - loss: 1.1624 - accuracy: 0.5494 - val_loss: 1.1533 - val_accuracy: 0.5658\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 353s 2s/step - loss: 1.0542 - accuracy: 0.6092 - val_loss: 1.0661 - val_accuracy: 0.5950\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 347s 2s/step - loss: 0.9383 - accuracy: 0.6502 - val_loss: 0.9875 - val_accuracy: 0.6275\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 428s 3s/step - loss: 0.8100 - accuracy: 0.6965 - val_loss: 0.8977 - val_accuracy: 0.6708\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 395s 3s/step - loss: 0.7060 - accuracy: 0.7456 - val_loss: 0.9351 - val_accuracy: 0.6583\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 452s 3s/step - loss: 0.6141 - accuracy: 0.7779 - val_loss: 0.8565 - val_accuracy: 0.6850\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 505s 3s/step - loss: 0.4922 - accuracy: 0.8185 - val_loss: 0.9299 - val_accuracy: 0.6808\n",
      "Epoch 12/50\n",
      "150/150 [==============================] - 547s 4s/step - loss: 0.4268 - accuracy: 0.8406 - val_loss: 0.9248 - val_accuracy: 0.6992\n",
      "Epoch 13/50\n",
      "150/150 [==============================] - 568s 4s/step - loss: 0.3562 - accuracy: 0.8656 - val_loss: 0.9233 - val_accuracy: 0.6950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c1810c7df0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 이미지 크기 설정\n",
    "img_size = (224, 224) # 이미지 크키가 크면 메모리를 많이 차지해서 설정 필요\n",
    "\n",
    "# 데이터 로드 및 전처리 함수\n",
    "def load_and_preprocess_data(image_paths, label, brightness=True):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # 랜덤하게 100장만 선택\n",
    "    selected_images = random.sample(image_paths, 1000) #1000개 이미지\n",
    "\n",
    "    for img_path in selected_images:\n",
    "        img = load_img(img_path, target_size=img_size)\n",
    "        img_array = img_to_array(img)\n",
    "\n",
    "        # 이미지 명도와 채도 높이기\n",
    "        if brightness:\n",
    "            img_array = cv2.convertScaleAbs(img_array, alpha=1.2, beta=30)\n",
    "\n",
    "        img_array = img_array.astype('float32') / 255.0  # 이미지를 0과 1 사이 값으로 정규화\n",
    "\n",
    "        data.append(img_array)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "\n",
    "# 카테고리 리스트\n",
    "categories = [\"joyful\", \"adventure\", \"tradition\", \"nature\", \"cultural\", \"art\"]\n",
    "num_classes = len(categories)\n",
    "\n",
    "# 이미지 데이터 로드 및 전처리\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    category_path = os.path.join(\"C:\\\\Users\\\\김현\\\\Final_Project\\\\crawled_img\", category) # crawled_img/안에 있는 카테고리 리스트\n",
    "    category_images = [os.path.join(category_path, img) for img in os.listdir(category_path)]\n",
    "    \n",
    "    data, labels = load_and_preprocess_data(category_images, label=i)\n",
    "    all_data.extend(data)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# 데이터 합치기 및 레이블 변환\n",
    "X = np.array(all_data)\n",
    "y = to_categorical(np.array(all_labels), num_classes=num_classes)\n",
    "\n",
    "# 학습 및 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# CNN 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))  # Dropout 추가\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))  # Dropout 추가\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))  # Dropout 추가\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout 추가\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# EarlyStopping 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16793927-e9d9-433e-ba95-53f52a2380e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 23s 612ms/step - loss: 0.9233 - accuracy: 0.6950\n",
      "테스트 손실: 0.9233\n",
      "테스트 정확도: 69.50%\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트에서 모델 평가\n",
    "evaluation_results = model.evaluate(X_test, y_test)\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(f'테스트 손실: {evaluation_results[0]:.4f}')\n",
    "print(f'테스트 정확도: {evaluation_results[1]*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e1a5db-20eb-4eaa-8121-331d8485919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model, load_model\n",
    "\n",
    "# 전체 모델 저장\n",
    "model.save(\"C:/Users/김현/Final_Project/epoch50_early.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
