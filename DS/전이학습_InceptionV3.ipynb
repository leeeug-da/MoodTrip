{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74237ede-14cd-41e6-84ef-cd8dcd65c9e5",
   "metadata": {},
   "source": [
    "# inceptionV3 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ddc9ce9-5a00-498e-8623-c27deefb33a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 12s 0us/step\n",
      "Epoch 1/50\n",
      "150/150 [==============================] - 1743s 11s/step - loss: 0.8869 - accuracy: 0.7165 - val_loss: 3.6187 - val_accuracy: 0.4225\n",
      "Epoch 2/50\n",
      "150/150 [==============================] - 1721s 11s/step - loss: 0.6071 - accuracy: 0.8110 - val_loss: 1.4630 - val_accuracy: 0.6033\n",
      "Epoch 3/50\n",
      "150/150 [==============================] - 1702s 11s/step - loss: 0.4910 - accuracy: 0.8535 - val_loss: 1.4250 - val_accuracy: 0.5833\n",
      "Epoch 4/50\n",
      "150/150 [==============================] - 1694s 11s/step - loss: 0.4439 - accuracy: 0.8637 - val_loss: 1.1359 - val_accuracy: 0.6400\n",
      "Epoch 5/50\n",
      "150/150 [==============================] - 1691s 11s/step - loss: 0.4016 - accuracy: 0.8748 - val_loss: 1.0966 - val_accuracy: 0.6633\n",
      "Epoch 6/50\n",
      "150/150 [==============================] - 1676s 11s/step - loss: 0.3584 - accuracy: 0.8904 - val_loss: 2.1149 - val_accuracy: 0.4950\n",
      "Epoch 7/50\n",
      "150/150 [==============================] - 1685s 11s/step - loss: 0.3280 - accuracy: 0.8963 - val_loss: 2.3170 - val_accuracy: 0.6975\n",
      "Epoch 8/50\n",
      "150/150 [==============================] - 1687s 11s/step - loss: 0.2609 - accuracy: 0.9169 - val_loss: 0.4855 - val_accuracy: 0.8517\n",
      "Epoch 9/50\n",
      "150/150 [==============================] - 1710s 11s/step - loss: 0.2325 - accuracy: 0.9300 - val_loss: 2.1128 - val_accuracy: 0.6475\n",
      "Epoch 10/50\n",
      "150/150 [==============================] - 1713s 11s/step - loss: 0.2155 - accuracy: 0.9315 - val_loss: 0.5816 - val_accuracy: 0.8267\n",
      "Epoch 11/50\n",
      "150/150 [==============================] - 1746s 12s/step - loss: 0.1938 - accuracy: 0.9440 - val_loss: 0.7962 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24db9bfc730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import DenseNet121, MobileNetV2, DenseNet201, EfficientNetB0, EfficientNetB1, InceptionV3, MobileNetV3Large, ResNet152V2, ResNet50, ResNet50V2, VGG19, VGG16, Xception\n",
    "\n",
    "# 이미지 크기 설정\n",
    "img_size = (224, 224)\n",
    "\n",
    "# 데이터 로드 및 전처리 함수\n",
    "def load_and_preprocess_data(image_paths, label, brightness=True):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    selected_images = random.sample(image_paths, 1000)\n",
    "\n",
    "    for img_path in selected_images:\n",
    "        img = load_img(img_path, target_size=img_size)\n",
    "        img_array = img_to_array(img)\n",
    "\n",
    "        if brightness:\n",
    "            img_array = cv2.convertScaleAbs(img_array, alpha=1.2, beta=30)\n",
    "\n",
    "        img_array = img_array.astype('float32') / 255.0\n",
    "\n",
    "        data.append(img_array)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# 카테고리 리스트\n",
    "categories = [\"joyful\", \"adventure\", \"tradition\", \"nature\", \"cultural\", \"art\"]\n",
    "num_classes = len(categories)\n",
    "\n",
    "# 이미지 데이터 로드 및 전처리\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    category_path = os.path.join(\"C:\\\\Users\\\\김현\\\\Final_Project\\\\crawled_img\", category)\n",
    "    category_images = [os.path.join(category_path, img) for img in os.listdir(category_path)]\n",
    "    \n",
    "    data, labels = load_and_preprocess_data(category_images, label=i)\n",
    "    all_data.extend(data)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# 데이터 합치기 및 레이블 변환\n",
    "X = np.array(all_data)\n",
    "y = to_categorical(np.array(all_labels), num_classes=num_classes)\n",
    "\n",
    "# 학습 및 테스트 데이터로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 사전 학습된 모델들\n",
    "models = {\n",
    "    \"DenseNet121\": DenseNet121,\n",
    "    \"MobileNetV2\": MobileNetV2,\n",
    "    \"DenseNet201\": DenseNet201,\n",
    "    \"EfficientNetB0\": EfficientNetB0,\n",
    "    \"EfficientNetB1\": EfficientNetB1,\n",
    "    \"InceptionV3\": InceptionV3,\n",
    "    \"MobileNetV3Large\": MobileNetV3Large,\n",
    "    \"ResNet152V2\": ResNet152V2,\n",
    "    \"ResNet50\": ResNet50,\n",
    "    \"ResNet50V2\": ResNet50V2,\n",
    "    \"VGG19\": VGG19,\n",
    "    \"VGG16\": VGG16,\n",
    "    \"Xception\": Xception\n",
    "}\n",
    "\n",
    "# 모델 선택\n",
    "base_model = models[\"InceptionV3\"](weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# 새로운 모델 생성\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# EarlyStopping 설정\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae3148c-8a21-4062-a49b-151af59fa813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 83s 2s/step - loss: 0.7962 - accuracy: 0.8125\n",
      "테스트 손실: 0.7962\n",
      "테스트 정확도: 81.25%\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트에서 모델 평가\n",
    "evaluation_results = model.evaluate(X_test, y_test)\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(f'테스트 손실: {evaluation_results[0]:.4f}')\n",
    "print(f'테스트 정확도: {evaluation_results[1]*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c25e5ce-fc02-4b69-99ab-b6f393743747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\김현\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import save_model, load_model\n",
    "\n",
    "# 전체 모델 저장\n",
    "model.save(\"C:/Users/김현/Final_Project/TL_inception.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
